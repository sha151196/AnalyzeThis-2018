{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahil/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/shahil/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as mn\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing function for columns\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        if feature_name!='application_key':# or feature_name!= \"application_key\" or feature_name!= \"default_ind\":\n",
    "            max_value = df[feature_name].max()\n",
    "            min_value = df[feature_name].min()\n",
    "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting specified number of columns with a certain NaN values\n",
    "\n",
    "def get_column(df):\n",
    "    feature_NA = []\n",
    "    for feature_name in df.columns:\n",
    "        if df[feature_name].isna().sum()>0.45*df.shape[0]:\n",
    "            feature_NA.append(feature_name)\n",
    "    return feature_NA\n",
    "\n",
    "#Dropping Columns\n",
    "def drop_column(df,feature_NA):\n",
    "    df = df.drop(columns=feature_NA,axis=1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_spliting(dataset):\n",
    "    #Converting dataset\n",
    "    dataset = dataset.replace(\"L\", 1, regex=True)\n",
    "    dataset = dataset.replace(\"C\", 0, regex=True)\n",
    "    dataset = dataset.replace(\"na\", np.nan, regex=True)\n",
    "    dataset = dataset.replace(\"missing\", np.nan, regex=True)\n",
    "    dataset=dataset.astype('float64')\n",
    "    \n",
    "    #Spliting C and L from dataset\n",
    "    dataC,dataL = [x for _, x in dataset.groupby(dataset['mvar47'] == 1.0)]\n",
    "    return dataC,dataL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_NA(dataC,dataL):\n",
    "    \n",
    "    #Removing Columns\n",
    "    \n",
    "    dataC= drop_column(dataC,featureC_NA_global)\n",
    "    dataL= drop_column(dataL,featureL_NA_global)\n",
    "    \n",
    "    #Removing rows containing high percentage of NaN values\n",
    "    \n",
    "    dataC = dataC.dropna(axis=0,thresh=0.75*dataC.shape[1])\n",
    "    dataL = dataL.dropna(axis=0,thresh=0.75*dataL.shape[1])\n",
    "    \n",
    "    #Normalizing data\n",
    "    dataC= normalize(dataC)\n",
    "    dataL= normalize(dataL)\n",
    "    \n",
    "    #imputing data\n",
    "    dataC = dataC.fillna(dataC.median())\n",
    "    dataL = dataL.fillna(dataL.median())\n",
    "    \n",
    "    return dataC,dataL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Training_dataset_Original.csv\", low_memory=False)\n",
    "dataset_lead = pd.read_csv(\"Leaderboard_dataset.csv\", low_memory=False)\n",
    "\n",
    "target = 'default_ind'\n",
    "IDcol = 'application_key'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataC, dataL = data_preprocess_spliting(dataset)\n",
    "dataC_lead, dataL_lead = data_preprocess_spliting(dataset_lead)\n",
    "\n",
    "featureC_NA_global = get_column(dataC)\n",
    "featureL_NA_global = get_column(dataL)\n",
    "\n",
    "dataC, dataL = data_preprocess_NA(dataC,dataL)\n",
    "dataC_lead, dataL_lead = data_preprocess_NA(dataC_lead,dataL_lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24662, 42) (40546, 43) (7723, 41) (12752, 42)\n"
     ]
    }
   ],
   "source": [
    "print dataL.shape, dataC.shape, dataL_lead.shape, dataC_lead.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataL = dataL.values[:,1:dataL.shape[1]-2]\n",
    "Y_dataL = dataL.values[:,dataL.shape[1]-1]\n",
    "X_dataC = dataC.values[:,1:dataC.shape[1]-2]\n",
    "Y_dataC = dataC.values[:,dataC.shape[1]-1]\n",
    "\n",
    "\n",
    "X_keyL_lead = dataL_lead.values[:,0]\n",
    "X_keyC_lead = dataC_lead.values[:,0]\n",
    "X_dataL_lead = dataL_lead.values[:,1:dataL_lead.shape[1]-1]\n",
    "X_dataC_lead = dataC_lead.values[:,1:dataC_lead.shape[1]-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24662, 39) (40546, 40) (7723, 39) (12752, 40)\n"
     ]
    }
   ],
   "source": [
    "print X_dataL.shape, X_dataC.shape, X_dataL_lead.shape, X_dataC_lead.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_dataL_train, X_dataL_test, Y_dataL_key1, Y_dataL_key2 = train_test_split( X_dataL, Y_dataL, test_size = 0.3, random_state = 18)\n",
    "#X_dataC_train, X_dataC_test, Y_dataC_key1, Y_dataC_key2 = train_test_split( X_dataC, Y_dataC, test_size = 0.3, random_state = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_dataL_test = Y_dataL_key2[:,1]\n",
    "#Y_dataC_test = Y_dataC_key2[:,1]\n",
    "#Y_dataL_train = Y_dataL_key1[:,1]\n",
    "#Y_dataC_train= Y_dataC_key1[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=2, early_stopping_rounds=5):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=2,\n",
    "            metrics='auc', early_stopping_rounds=5)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['application_key'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in dataL.columns if x not in [target, IDcol]]\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.2,\n",
    " n_estimators=100,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, dataL, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in dataC.columns if x not in [target, IDcol]]\n",
    "\n",
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, dataC, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-a6eb9153e730>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-a6eb9153e730>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    'eval_metric': 'auc',\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "params={\n",
    "    'booster':'gbtree',\n",
    "       'objective': 'binary:logistic',\n",
    "    'n_estimators':1000\n",
    "       'eval_metric': 'auc',\n",
    "      'max_depth':4,\n",
    "      'subsample':0.75,\n",
    "      'colsample_bytree':0.75,\n",
    "    'min_child_weight':2,\n",
    "        'eta': 0.025,\n",
    "        'seed':0,\n",
    "        'nthread':8,\n",
    "        'silent':1\n",
    "       }\n",
    "# fit model no training data\n",
    "model_L = XGBClassifier(**params)\n",
    "model_L.fit(X_dataL, Y_dataL)\n",
    "# make predictions for test data\n",
    "y_prob_L = model_L.predict_proba(X_dataL_lead)\n",
    "y_pred_L = model_L.predict(X_dataL_lead)\n",
    "\n",
    "predictions = [round(value) for value in y_pred_L]\n",
    "# evaluate predictions\n",
    "#accuracy = accuracy_score(Y_dataL_test, y_pred_L)\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "#Event_Probability_L and DataFrame  creation\n",
    "event_prob_L = np.amax(y_prob_L, axis=1)\n",
    "d_L= {\"application_key\":X_keyL_lead, \"y_pred\" : y_pred_L,\"event_prob\" : event_prob_L}\n",
    "df_L = pd.DataFrame(data=d_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-f27cef57f5b8>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-f27cef57f5b8>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    'max_depth':4,\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#XBoost on C\n",
    "params={\n",
    "    'booster':'gbtree',\n",
    "       'objective': 'binary:logistic',\n",
    "       'eval_metric': 'auc',\n",
    "        'n_estimators':1000\n",
    "      'max_depth':4,\n",
    "      'subsample':0.75,\n",
    "      'colsample_bytree':0.75,\n",
    "    'min_child_weight':2,\n",
    "        'eta': 0.025,\n",
    "        'seed':0,\n",
    "        'nthread':8,\n",
    "        'silent':1\n",
    "       }\n",
    "# fit model no training data\n",
    "model_C = XGBClassifier(**params)\n",
    "model_C.fit(X_dataC, Y_dataC)\n",
    "# make predictions for test data\n",
    "y_prob_C = model_C.predict_proba(X_dataC_lead)\n",
    "y_pred_C = model_C.predict(X_dataC_lead)\n",
    "\n",
    "predictions = [round(value) for value in y_pred_C]\n",
    "# evaluate predictions\n",
    "#accuracy = accuracy_score(Y_dataC_test, y_pred_C)\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "#Event_Probability_C and DataFrame  creation\n",
    "event_prob_C = np.amax(y_prob_C, axis=1)\n",
    "d_C= {\"application_key\":X_keyC_lead, \"y_pred\" : y_pred_C,\"event_prob\" : event_prob_C}\n",
    "#print X_keyC_lead, y_pred_C, event_prob_C\n",
    "df_C = pd.DataFrame(data=d_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_key</th>\n",
       "      <th>event_prob</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350054.0</td>\n",
       "      <td>0.952037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350055.0</td>\n",
       "      <td>0.867250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>350062.0</td>\n",
       "      <td>0.679058</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350063.0</td>\n",
       "      <td>0.933493</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350064.0</td>\n",
       "      <td>0.769867</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>350065.0</td>\n",
       "      <td>0.704683</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>350066.0</td>\n",
       "      <td>0.562293</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>350067.0</td>\n",
       "      <td>0.698252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>350070.0</td>\n",
       "      <td>0.897706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>350071.0</td>\n",
       "      <td>0.869619</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>350072.0</td>\n",
       "      <td>0.805551</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>350073.0</td>\n",
       "      <td>0.798385</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>350074.0</td>\n",
       "      <td>0.529320</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>350075.0</td>\n",
       "      <td>0.986907</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>350076.0</td>\n",
       "      <td>0.766579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>350079.0</td>\n",
       "      <td>0.732442</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>350080.0</td>\n",
       "      <td>0.854579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>350081.0</td>\n",
       "      <td>0.865229</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>350082.0</td>\n",
       "      <td>0.884164</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>350084.0</td>\n",
       "      <td>0.641672</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>350086.0</td>\n",
       "      <td>0.718869</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>350087.0</td>\n",
       "      <td>0.809705</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>350089.0</td>\n",
       "      <td>0.697321</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>350091.0</td>\n",
       "      <td>0.964215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>350092.0</td>\n",
       "      <td>0.957588</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>350093.0</td>\n",
       "      <td>0.720124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>350095.0</td>\n",
       "      <td>0.663772</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>350096.0</td>\n",
       "      <td>0.651739</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>350126.0</td>\n",
       "      <td>0.611738</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>350128.0</td>\n",
       "      <td>0.911450</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7693</th>\n",
       "      <td>374967.0</td>\n",
       "      <td>0.961683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>374969.0</td>\n",
       "      <td>0.969853</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>374970.0</td>\n",
       "      <td>0.528563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>374977.0</td>\n",
       "      <td>0.630871</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>374978.0</td>\n",
       "      <td>0.933827</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>374979.0</td>\n",
       "      <td>0.994247</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>374980.0</td>\n",
       "      <td>0.962077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7700</th>\n",
       "      <td>374981.0</td>\n",
       "      <td>0.985095</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>374983.0</td>\n",
       "      <td>0.994012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>374984.0</td>\n",
       "      <td>0.764101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>374987.0</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>374995.0</td>\n",
       "      <td>0.932276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>375002.0</td>\n",
       "      <td>0.990802</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7706</th>\n",
       "      <td>375004.0</td>\n",
       "      <td>0.848933</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7707</th>\n",
       "      <td>375005.0</td>\n",
       "      <td>0.982520</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7708</th>\n",
       "      <td>375007.0</td>\n",
       "      <td>0.840762</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>375009.0</td>\n",
       "      <td>0.938820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>375015.0</td>\n",
       "      <td>0.980895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>375016.0</td>\n",
       "      <td>0.836581</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>375017.0</td>\n",
       "      <td>0.521387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7713</th>\n",
       "      <td>375020.0</td>\n",
       "      <td>0.909433</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7714</th>\n",
       "      <td>375021.0</td>\n",
       "      <td>0.814826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7715</th>\n",
       "      <td>375023.0</td>\n",
       "      <td>0.857582</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>375024.0</td>\n",
       "      <td>0.960068</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>375030.0</td>\n",
       "      <td>0.945251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7718</th>\n",
       "      <td>375033.0</td>\n",
       "      <td>0.993516</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>375036.0</td>\n",
       "      <td>0.862395</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7720</th>\n",
       "      <td>375044.0</td>\n",
       "      <td>0.973218</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7721</th>\n",
       "      <td>375045.0</td>\n",
       "      <td>0.519765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7722</th>\n",
       "      <td>375049.0</td>\n",
       "      <td>0.979506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20475 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      application_key  event_prob  y_pred\n",
       "0            350054.0    0.952037     0.0\n",
       "1            350055.0    0.867250     0.0\n",
       "2            350062.0    0.679058     0.0\n",
       "3            350063.0    0.933493     0.0\n",
       "4            350064.0    0.769867     0.0\n",
       "5            350065.0    0.704683     1.0\n",
       "6            350066.0    0.562293     1.0\n",
       "7            350067.0    0.698252     0.0\n",
       "8            350070.0    0.897706     0.0\n",
       "9            350071.0    0.869619     0.0\n",
       "10           350072.0    0.805551     0.0\n",
       "11           350073.0    0.798385     0.0\n",
       "12           350074.0    0.529320     1.0\n",
       "13           350075.0    0.986907     0.0\n",
       "14           350076.0    0.766579     0.0\n",
       "15           350079.0    0.732442     0.0\n",
       "16           350080.0    0.854579     0.0\n",
       "17           350081.0    0.865229     1.0\n",
       "18           350082.0    0.884164     0.0\n",
       "19           350084.0    0.641672     1.0\n",
       "20           350086.0    0.718869     0.0\n",
       "21           350087.0    0.809705     0.0\n",
       "22           350089.0    0.697321     0.0\n",
       "23           350091.0    0.964215     0.0\n",
       "24           350092.0    0.957588     0.0\n",
       "25           350093.0    0.720124     0.0\n",
       "26           350095.0    0.663772     0.0\n",
       "27           350096.0    0.651739     1.0\n",
       "28           350126.0    0.611738     1.0\n",
       "29           350128.0    0.911450     0.0\n",
       "...               ...         ...     ...\n",
       "7693         374967.0    0.961683     0.0\n",
       "7694         374969.0    0.969853     0.0\n",
       "7695         374970.0    0.528563     1.0\n",
       "7696         374977.0    0.630871     0.0\n",
       "7697         374978.0    0.933827     0.0\n",
       "7698         374979.0    0.994247     0.0\n",
       "7699         374980.0    0.962077     0.0\n",
       "7700         374981.0    0.985095     0.0\n",
       "7701         374983.0    0.994012     0.0\n",
       "7702         374984.0    0.764101     0.0\n",
       "7703         374987.0    0.929577     0.0\n",
       "7704         374995.0    0.932276     0.0\n",
       "7705         375002.0    0.990802     0.0\n",
       "7706         375004.0    0.848933     0.0\n",
       "7707         375005.0    0.982520     0.0\n",
       "7708         375007.0    0.840762     0.0\n",
       "7709         375009.0    0.938820     0.0\n",
       "7710         375015.0    0.980895     0.0\n",
       "7711         375016.0    0.836581     0.0\n",
       "7712         375017.0    0.521387     0.0\n",
       "7713         375020.0    0.909433     0.0\n",
       "7714         375021.0    0.814826     0.0\n",
       "7715         375023.0    0.857582     0.0\n",
       "7716         375024.0    0.960068     0.0\n",
       "7717         375030.0    0.945251     0.0\n",
       "7718         375033.0    0.993516     0.0\n",
       "7719         375036.0    0.862395     0.0\n",
       "7720         375044.0    0.973218     0.0\n",
       "7721         375045.0    0.519765     1.0\n",
       "7722         375049.0    0.979506     0.0\n",
       "\n",
       "[20475 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating C and L\n",
    "frames = [df_C, df_L]\n",
    "Final_result = pd.concat(frames)\n",
    "Final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_result.to_csv(\"dfghj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
